{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04b5736-0e0e-4b5d-a83d-2b5265489d76",
   "metadata": {},
   "source": [
    "# Deploying Stable Diffusion using Stability AI DLC on AWS SageMaker\n",
    "\n",
    "## Example: Stable Diffusion XL v1.0 on PyTorch 2.0.1\n",
    "\n",
    "This example (based on https://github.com/Stability-AI/aws-dlc-examples/tree/main) will deploy an endpoint running Stable Diffusion XL on AWS SageMaker using the Stability AI DLC. This example can provide inference as-is or serve as a basis for custom development & deployment scenarios.\n",
    "\n",
    "If you are looking for a production-ready, turnkey solution for inference with a full-featured API, check out [SDXL on AWS Marketplace](https://aws.amazon.com/marketplace/seller-profile?id=seller-mybtdwpr2puau) and the related [Jumpstart notebooks](https://github.com/Stability-AI/aws-jumpstart-examples)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cb48a33",
   "metadata": {},
   "source": [
    "# Supported regions for this example\n",
    "\n",
    "This example uses g5 instances. Particularly, a minimum requirement is to use g5.4xlarge instances.\n",
    "\n",
    "G5 family instances are not available in every region. As a result, we recommend you use one of the following regions for your example.\n",
    "\n",
    "- us-east-1 (Virginia)\n",
    "- us-east-2 (Ohio)\n",
    "- us-west-2 (Oregon)\n",
    "- ca-central-1 (Canada)\n",
    "- eu-west-1 (Ireland)\n",
    "- eu-central-1 (Frankfurt)\n",
    "- eu-west-2 (London)\n",
    "- ap-northeast-1 (Tokyo)\n",
    "- ap-south-1 (Mumbai)\n",
    "- ap-northeast-2 (Seoul)\n",
    "- ap-southeast-2 (Sydney)\n",
    "- sa-east-1 (Sao Paulo)\n",
    "\n",
    "Source - https://aws.amazon.com/about-aws/whats-new/2023/06/amazon-ec2-g5-instances-additional-regions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6c8d5-23e0-49e4-b554-28cbc671a743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/home/duck/.pyenv/versions/3.11.6/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/duck/.pyenv/versions/3.11.6/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# NOTE: You may have to restart your kernel after installing boto3\n",
    "!pip install \"sagemaker\" \"huggingface_hub\" \"boto3\" --upgrade --quiet\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import ModelPackage, get_execution_role\n",
    "\n",
    "from PIL import Image\n",
    "from typing import Union, Tuple\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "import boto3\n",
    "\n",
    "aws_region = \"us-east-1\"\n",
    "# In order to upload SageMaker ModelPackage, we need to have a bucket in the same region as the SageMaker endpoint and permission to read and write to it.\n",
    "sagemaker_model_bucket=\"sagemak-develop-modelbucket-dwv1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149960eb-61a6-45d9-9a5b-7ba78cf28be4",
   "metadata": {},
   "source": [
    "## 1. Download the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bffc4-2794-4b28-ad33-92d736e425bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "local_dir = './model'\n",
    "snapshot_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    allow_patterns=\"sd_xl_base_1.0.safetensors\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "snapshot_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "    allow_patterns=\"sd_xl_refiner_1.0.safetensors\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edf97d-2751-41a7-9d2f-dd8cba8f2c1f",
   "metadata": {},
   "source": [
    "## 2. Custom Inference Script Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38662e-1459-49c0-a0d1-ca84e48c7336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p model/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22537ff5-c48b-40e4-9bb2-f5585407e478",
   "metadata": {},
   "source": [
    "### Inference Script: Text2Image, Image2Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c695fe0-9192-46da-84be-8d33b8d94e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model/code/inference.py\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from einops import rearrange\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pytorch_lightning import seed_everything\n",
    "import numpy as np\n",
    "from sagemaker_inference.errors import BaseInferenceToolkitError\n",
    "import sgm\n",
    "from sgm.inference.api import (\n",
    "    ModelArchitecture,\n",
    "    SamplingParams,\n",
    "    SamplingPipeline,\n",
    "    Sampler,\n",
    "    get_sampler_config,\n",
    ")\n",
    "from sgm.inference.helpers import (\n",
    "    get_input_image_tensor,\n",
    "    embed_watermark,\n",
    "    do_img2img,\n",
    "    Img2ImgDiscretizationWrapper,\n",
    ")\n",
    "import os\n",
    "\n",
    "\n",
    "def model_fn(model_dir, context=None):\n",
    "    # Enable the refiner by default\n",
    "    disable_refiner = os.environ.get(\"SDXL_DISABLE_REFINER\", \"false\").lower() == \"true\"\n",
    "\n",
    "    sgm_path = os.path.dirname(sgm.__file__)\n",
    "    config_path = os.path.join(sgm_path, \"configs/inference\")\n",
    "    if not os.path.exists(config_path):\n",
    "        config_path = os.path.join(sgm_path, \"../configs/inference\")\n",
    "    base_pipeline = SamplingPipeline(\n",
    "        ModelArchitecture.SDXL_V1_BASE, model_path=model_dir, config_path=config_path\n",
    "    )\n",
    "    if disable_refiner:\n",
    "        print(\"Refiner model disabled by SDXL_DISABLE_REFINER environment variable\")\n",
    "        refiner_pipeline = None\n",
    "    else:\n",
    "        refiner_pipeline = SamplingPipeline(\n",
    "            ModelArchitecture.SDXL_V1_REFINER,\n",
    "            model_path=model_dir,\n",
    "            config_path=config_path,\n",
    "        )\n",
    "\n",
    "    return {\"base\": base_pipeline, \"refiner\": refiner_pipeline}\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == \"application/json\":\n",
    "        model_input = json.loads(request_body)\n",
    "        if not \"text_prompts\" in model_input:\n",
    "            raise BaseInferenceToolkitError(\n",
    "                400, \"Invalid Request\", \"text_prompts missing\"\n",
    "            )\n",
    "        return model_input\n",
    "    else:\n",
    "        raise BaseInferenceToolkitError(\n",
    "            400, \"Invalid Request\", \"Content-type must be application/json\"\n",
    "        )\n",
    "\n",
    "\n",
    "def predict_fn(data, model, context=None):\n",
    "    # Only a single positive and optionally a single negative prompt are supported by this example.\n",
    "    prompts = []\n",
    "    negative_prompts = []\n",
    "    if \"text_prompts\" in data:\n",
    "        for text_prompt in data[\"text_prompts\"]:\n",
    "            if \"text\" not in text_prompt:\n",
    "                raise BaseInferenceToolkitError(\n",
    "                    400, \"Invalid Request\", \"text missing from text_prompt\"\n",
    "                )\n",
    "            if \"weight\" not in text_prompt:\n",
    "                text_prompt[\"weight\"] = 1.0\n",
    "            if text_prompt[\"weight\"] < 0:\n",
    "                negative_prompts.append(text_prompt[\"text\"])\n",
    "            else:\n",
    "                prompts.append(text_prompt[\"text\"])\n",
    "\n",
    "    if len(prompts) != 1:\n",
    "        raise BaseInferenceToolkitError(\n",
    "            400,\n",
    "            \"Invalid Request\",\n",
    "            \"One prompt with positive or default weight must be supplied\",\n",
    "        )\n",
    "    if len(negative_prompts) > 1:\n",
    "        raise BaseInferenceToolkitError(\n",
    "            400, \"Invalid Request\", \"Only one negative weighted prompt can be supplied\"\n",
    "        )\n",
    "\n",
    "    seed = 0\n",
    "    height = 1024\n",
    "    width = 1024\n",
    "    sampler_name = \"DPMPP2MSampler\"\n",
    "    cfg_scale = 7.0\n",
    "    steps = 40\n",
    "    use_refiner = model[\"refiner\"] is not None\n",
    "    init_image = None\n",
    "    image_strength = 0.35\n",
    "    refiner_steps = 40\n",
    "    refiner_strength = 0.2\n",
    "\n",
    "    if \"height\" in data:\n",
    "        height = data[\"height\"]\n",
    "    if \"width\" in data:\n",
    "        width = data[\"width\"]\n",
    "    if \"sampler\" in data:\n",
    "        sampler_name = data[\"sampler\"]\n",
    "    if \"cfg_scale\" in data:\n",
    "        cfg_scale = data[\"cfg_scale\"]\n",
    "    if \"steps\" in data:\n",
    "        steps = data[\"steps\"]\n",
    "    if \"seed\" in data:\n",
    "        seed = data[\"seed\"]\n",
    "        seed_everything(seed)\n",
    "    if \"use_refiner\" in data:\n",
    "        use_refiner = data[\"use_refiner\"]\n",
    "    if use_refiner:\n",
    "        if \"refiner_steps\" in data:\n",
    "            refiner_steps = data[\"refiner_steps\"]\n",
    "        if \"refiner_strength\" in data:\n",
    "            refiner_strength = data[\"refiner_strength\"]\n",
    "    if \"init_image\" in data:\n",
    "        if \"image_strength\" in data:\n",
    "            image_strength = data[\"image_strength\"]\n",
    "        try:\n",
    "            init_image_bytes = BytesIO(base64.b64decode(data[\"init_image\"]))\n",
    "            init_image_bytes.seek(0)\n",
    "            if init_image_bytes is not None:\n",
    "                init_image = get_input_image_tensor(Image.open(init_image_bytes))\n",
    "        except Exception as e:\n",
    "            raise BaseInferenceToolkitError(\n",
    "                400, \"Invalid Request\", \"Unable to decode init_image\"\n",
    "            )\n",
    "\n",
    "    if model[\"refiner\"] is None and use_refiner:\n",
    "        raise BaseInferenceToolkitError(\n",
    "            400, \"Invalid Request\", \"Pipeline is not available\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        if init_image is not None:\n",
    "            img_height, img_width = init_image.shape[2], init_image.shape[3]\n",
    "            output = model[\"base\"].image_to_image(\n",
    "                params=SamplingParams(\n",
    "                    width=img_width,\n",
    "                    height=img_height,\n",
    "                    steps=steps,\n",
    "                    sampler=Sampler(sampler_name),\n",
    "                    scale=cfg_scale,\n",
    "                    img2img_strength=image_strength,\n",
    "                ),\n",
    "                image=init_image,\n",
    "                prompt=prompts[0],\n",
    "                negative_prompt=negative_prompts[0]\n",
    "                if len(negative_prompts) > 0\n",
    "                else \"\",\n",
    "                return_latents=use_refiner,\n",
    "            )\n",
    "        else:\n",
    "            output = model[\"base\"].text_to_image(\n",
    "                params=SamplingParams(\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                    steps=steps,\n",
    "                    sampler=Sampler(sampler_name),\n",
    "                    scale=cfg_scale,\n",
    "                ),\n",
    "                prompt=prompts[0],\n",
    "                negative_prompt=negative_prompts[0]\n",
    "                if len(negative_prompts) > 0\n",
    "                else \"\",\n",
    "                return_latents=use_refiner,\n",
    "            )\n",
    "\n",
    "        if isinstance(output, (tuple, list)):\n",
    "            samples, samples_z = output\n",
    "        else:\n",
    "            samples = output\n",
    "            samples_z = None\n",
    "\n",
    "        if use_refiner and samples_z is not None:\n",
    "            print(\"Running Refinement Stage\")\n",
    "            samples = refiner(\n",
    "                model=model[\"refiner\"].model,\n",
    "                params=SamplingParams(\n",
    "                    steps=refiner_steps,\n",
    "                    sampler=Sampler.EULER_EDM,\n",
    "                    scale=5.0,\n",
    "                    img2img_strength=refiner_strength,\n",
    "                ),\n",
    "                image=samples_z,\n",
    "                prompt=prompts[0],\n",
    "                negative_prompt=negative_prompts[0]\n",
    "                if len(negative_prompts) > 0\n",
    "                else \"\",\n",
    "            )\n",
    "\n",
    "        samples = embed_watermark(samples)\n",
    "        images = []\n",
    "        for sample in samples:\n",
    "            sample = 255.0 * rearrange(sample.cpu().numpy(), \"c h w -> h w c\")\n",
    "            image_bytes = BytesIO()\n",
    "            Image.fromarray(sample.astype(np.uint8)).save(image_bytes, format=\"PNG\")\n",
    "            image_bytes.seek(0)\n",
    "            images.append(image_bytes.read())\n",
    "\n",
    "        return images\n",
    "\n",
    "    except ValueError as e:\n",
    "        raise BaseInferenceToolkitError(400, \"Invalid Request\", str(e))\n",
    "\n",
    "\n",
    "# fixed version of refiner function from sgm 0.1.1\n",
    "def wrap_discretization(discretization, strength=1.0):\n",
    "    if not isinstance(discretization, Img2ImgDiscretizationWrapper) and strength < 1.0:\n",
    "        return Img2ImgDiscretizationWrapper(discretization, strength=strength)\n",
    "    return discretization\n",
    "\n",
    "\n",
    "def refiner(\n",
    "    model,\n",
    "    image,\n",
    "    prompt: str,\n",
    "    negative_prompt: str = \"\",\n",
    "    params: SamplingParams = SamplingParams(\n",
    "        sampler=Sampler.EULER_EDM, steps=40, img2img_strength=0.2\n",
    "    ),\n",
    "    samples: int = 1,\n",
    "    return_latents: bool = False,\n",
    "):\n",
    "    sampler = get_sampler_config(params)\n",
    "    value_dict = {\n",
    "        \"orig_width\": image.shape[3] * 8,\n",
    "        \"orig_height\": image.shape[2] * 8,\n",
    "        \"target_width\": image.shape[3] * 8,\n",
    "        \"target_height\": image.shape[2] * 8,\n",
    "        \"prompt\": prompt,\n",
    "        \"negative_prompt\": negative_prompt,\n",
    "        \"crop_coords_top\": 0,\n",
    "        \"crop_coords_left\": 0,\n",
    "        \"aesthetic_score\": 6.0,\n",
    "        \"negative_aesthetic_score\": 2.5,\n",
    "    }\n",
    "\n",
    "    sampler.discretization = wrap_discretization(\n",
    "        sampler.discretization, strength=params.img2img_strength\n",
    "    )\n",
    "\n",
    "    return do_img2img(\n",
    "        image,\n",
    "        model,\n",
    "        sampler,\n",
    "        value_dict,\n",
    "        samples,\n",
    "        skip_encode=True,\n",
    "        return_latents=return_latents,\n",
    "        filter=None,\n",
    "    )\n",
    "\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    # This only returns a single image since that's all the example code supports\n",
    "    if accept != \"image/png\":\n",
    "        raise BaseInferenceToolkitError(\n",
    "            400, \"Invalid Request\", \"Accept header must be image/png\"\n",
    "        )\n",
    "    return prediction[0], accept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb15579-a52b-4d5f-8bc6-76698e0295ac",
   "metadata": {},
   "source": [
    "## 3. Package and upload model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3d986-6b7f-4308-a2cf-983541040d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_model_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d436a-9c5e-4992-8d65-a529477d4a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rerun this cell only if you need to re-upload the weights, otherwise you can reuse the existing model_package_name and upload only your new code \n",
    "from sagemaker.utils import name_from_base\n",
    "model_package_name = name_from_base(f\"sdxl-v1\") # You may want to make this a fixed name of your choosing instead\n",
    "model_uri = f's3://{sagemaker_model_bucket}/{model_package_name}/'\n",
    "\n",
    "print(f'Uploading base model to {model_uri}, this will take a while...')\n",
    "!aws s3 cp model/sd_xl_base_1.0.safetensors {model_uri}\n",
    "print(f'Uploading refiner model to {model_uri}, this will take a while...')\n",
    "!aws s3 cp model/sd_xl_refiner_1.0.safetensors {model_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455a3b9-96d0-4fc1-a0b0-f7508c90018e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rerun this cell when you have changed the code or are uploading a fresh copy of the weights\n",
    "print(f'Uploading code to {model_uri}code')\n",
    "!aws s3 cp model/code/inference.py {model_uri}code/inference.py\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd6072-9ef6-4a32-b93a-87f7067a1183",
   "metadata": {},
   "source": [
    "## 4. Create and deploy a model and perform real-time inference\n",
    "\n",
    "boto3 is being used to deploy the model here to take advantage of [Uncompressed model downloads](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-uncompressed.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd680a-7af0-4060-ba62-25341dd58973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please only use regions with g5 instance support, mentioned at the top of this page\n",
    "inference_image_uri_region = aws_region\n",
    "\n",
    "# AWS Account for AWS's publicly accessible DLC (Deep Learning Containers) ECR\n",
    "inference_image_uri_region_acct = \"763104351884\"\n",
    "\n",
    "inference_image_uri = f\"{inference_image_uri_region_acct}.dkr.ecr.{inference_image_uri_region}.amazonaws.com/stabilityai-pytorch-inference:2.0.1-sgm0.1.0-gpu-py310-cu118-ubuntu20.04-sagemaker\"\n",
    "\n",
    "\n",
    "print(\"You will need the inference_image_uri for your model creation in Massdriver:\")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673db27-8c8e-4815-b6b3-afff123dac63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = name_from_base(f\"sdxl-v1\")\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "# Creates the model and saves it to the model registry\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = endpoint_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataSource\": {\n",
    "            \"S3DataSource\": {               # S3 Data Source configuration:\n",
    "                \"S3Uri\": model_uri,         # path to your model and script\n",
    "                \"S3DataType\": \"S3Prefix\",   # causes SageMaker to download from a prefix\n",
    "                \"CompressionType\": \"None\"   # disables compression\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Creates the endpoint configuration for the model\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_name,\n",
    "    ProductionVariants = [{\n",
    "        \"ModelName\": endpoint_name,\n",
    "        \"VariantName\": \"sdxl\",\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.g5.4xlarge\",     # 4xlarge is required to load the model\n",
    "    }]\n",
    ")\n",
    "        \n",
    "# Creates the inference endpoint\n",
    "deploy_model_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    EndpointConfigName = endpoint_name\n",
    ")\n",
    "    \n",
    "print('Waiting for the endpoint to be in service, this can take 5-10 minutes...')\n",
    "waiter = sagemaker_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "print(f'Endpoint {endpoint_name} is in service, but the model is still loading. This may take another 5-10 minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd21303-b63a-4ec1-ac2f-83cf79e22084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import BytesDeserializer\n",
    "\n",
    "# Create a predictor with proper serializers\n",
    "deployed_model = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sess,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=BytesDeserializer(accept=\"image/png\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9378b7-9bdc-41bf-a7b4-401c6de94b1c",
   "metadata": {},
   "source": [
    "## A. Text to image\n",
    "\n",
    "**Note**: The endpoint will be \"InService\" before the model has finished loading, so this request will initially time out. Check the endpoint logs in CloudWatch for status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6099f66-3390-4b54-9121-b1be5a44e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to display images\n",
    "def decode_and_show(model_response) -> None:\n",
    "    \"\"\"\n",
    "    Decodes and displays an image from SDXL output\n",
    "\n",
    "    Args:\n",
    "        model_response (GenerationResponse): The response object from the deployed SDXL model.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"        \n",
    "    image = Image.open(io.BytesIO(model_response))\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8cdb1a-f6aa-4350-b241-ef1b240e789d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = deployed_model.predict({\"text_prompts\":[{\"text\": \"jaguar in the Amazon rainforest\"}],                                             \n",
    "                                             \"seed\": 133,\n",
    "                                            \"width\": 1024,\n",
    "                                            \"height\": 1024})\n",
    "decode_and_show(output)                                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb2e0e-d037-4825-a965-3af699c0e5be",
   "metadata": {
    "tags": []
   },
   "source": [
    "Available samplers are:\n",
    "```\n",
    "“EulerEDMSampler”,\n",
    "“HeunEDMSampler”,\n",
    "“EulerAncestralSampler”,\n",
    "“DPMPP2SAncestralSampler”,\n",
    "“DPMPP2MSampler”,\n",
    "“LinearMultistepSampler”,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a36034-70cb-424d-af63-6193b5b99f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"photograph of latte art of a cat\"\n",
    "\n",
    "output = deployed_model.predict({\"text_prompts\":[{\"text\":text}],\n",
    "                                            \"seed\":45,\n",
    "                                            \"height\":640,\n",
    "                                            \"width\":1536,\n",
    "                                            \"sampler\":\"EulerEDMSampler\",\n",
    "                                })\n",
    "decode_and_show(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e397ce-c11d-4a2d-91f7-46839a4638d0",
   "metadata": {},
   "source": [
    "SDXL can render short snippets of text, like single words. Let's try an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b02cc3-3d1d-4af7-aaa5-492fb05dbb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"the word go written in neon lights\"\n",
    "\n",
    "output = deployed_model.predict({\"text_prompts\":[{\"text\":text}],                                            \n",
    "                                            \"seed\": 142,\n",
    "                                            \"height\": 640,\n",
    "                                            \"width\": 1536,\n",
    "                                            \"sampler\": \"LinearMultistepSampler\",\n",
    "                                })\n",
    "decode_and_show(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d0135-1a61-4d4e-a555-10465fe40e35",
   "metadata": {},
   "source": [
    "## B. Image to image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9bad7-ac4d-413c-8f3b-e2ca2cd6a210",
   "metadata": {},
   "source": [
    "To perform inference that takes an image as input, you must pass the image into `init_image` as a base64-encoded string.\n",
    "\n",
    "Below is a helper function for converting images to base64-encoded strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5faa61-01ee-4bb4-ace7-22c402cc445d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_image(image_path: str, resize: bool = True, size: Tuple[int, int] = (1024, 1024)) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Encode an image as a base64 string, optionally resizing it to a supported resolution.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        resize (bool, optional): Whether to resize the image. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Union[str, None]: The encoded image as a string, or None if encoding failed.\n",
    "    \"\"\"\n",
    "    assert os.path.exists(image_path)\n",
    "\n",
    "    if resize:\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize(size)\n",
    "        image.save(\"image_path_resized.png\")\n",
    "        image_path = \"image_path_resized.png\"\n",
    "    image = Image.open(image_path)\n",
    "    assert image.size == size\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        img_byte_array = image_file.read()\n",
    "        # Encode the byte array as a Base64 string\n",
    "        try:\n",
    "            base64_str = base64.b64encode(img_byte_array).decode(\"utf-8\")\n",
    "            return base64_str\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to encode image {image_path} as base64 string.\")\n",
    "            print(e)\n",
    "            return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184979a1-9072-4e21-903d-ef7d689fe1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://platform.stability.ai/Cat_August_2010-4.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad064f1-5fec-40cd-acac-6e67e5ae3407",
   "metadata": {},
   "source": [
    "Let's feed an image into the model as well as the prompt this time. We can set `image_scale` to weight the relative importance of the image and the prompt. For the demo, we'll use a [picture of the cat, taken from Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Cat_August_2010-4.jpg), provided along with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30c1ff-3762-4ede-ad11-306070d741a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is the original image:\n",
    "display(Image.open('Cat_August_2010-4.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bba40-805b-42ab-a2c9-2eaf5810a0f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_path = \"Cat_August_2010-4.jpg\"\n",
    "\n",
    "size = (1536, 640)\n",
    "cat_data = encode_image(cat_path, size=size)\n",
    "\n",
    "output = deployed_model.predict({\"text_prompts\":[{\"text\": \"cat in embroidery\"}],\n",
    "                                                  \"init_image\": cat_data,\n",
    "                                                  \"cfg_scale\": 9,\n",
    "                                                  \"image_strength\": 0.8,\n",
    "                                                  \"seed\": 42,\n",
    "                                                  })                                            \n",
    "decode_and_show(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132aa646-f84d-40d0-ab1d-7d3a04c1ce0f",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[3: Delete the endpoint](#toc0_)\n",
    "\n",
    "When you've finished working, you can delete the endpoint to release the EC2 instance(s) associated with it, and stop billing.\n",
    "\n",
    "Get your list of Sagemaker endpoints using the AWS Sagemaker CLI like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54f8af-0c13-4ef5-9b19-665a8db1befa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws sagemaker list-endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3312cc-b58b-4058-8073-4d298f77382d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Delete an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a79e2e-714a-464c-be54-96c60ade8fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "# Rerun the aws cli command above to confirm that its gone."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
